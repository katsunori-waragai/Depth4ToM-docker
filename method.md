3. 方法 我々の目標は、安価でスケーラブルな方法で、ToMオブジェクトを特徴とする画像の深度アノテーションを生成することである。これにより、ディープネットワークを訓練して、カメラを通して屈折／反射されたシーンコンテンツの距離ではなく、カメラの正面にある最も近い表面の距離として適切に奥行きを推定することができる。我々の戦略はシンプルでありながら劇的に効果的であり、ToM表面を扱うのに苦労しているものの、様々なシーンに渡って強力な汎化が可能な、最近の事前訓練された単眼奥行き推定モデル[37, 36]の利用可能性に依存している。   このような現状を踏まえ、我々は、ToMオブジェクトは、多くの場合、最近の事前訓練された単眼奥行き推定ネットワークの信頼性を損なう唯一の要素であると主張する。   したがって、これらのオブジェクトを、全く同じ形状に似せたテクスチャ付き人工物で仮想的に置き換えることで、単眼モデルは、理想的にはシーン内の全く同じ場所に配置された不透明なオブジェクトの奥行きを推定するように、騙され誘導される可能性がある。この方法論は、手動アノテーションまたはセグメンテーションネットワークによってToMオブジェクトを画定し、画像からそれらをマスクし、マスクされた領域内に仮想テクスチャをインペイントすることによって実現できる。一方では、ToMオブジェクトの適切な検出は我々の方法論にとって極めて重要であるため、手作業によるラベリングが最も正確な選択になることは間違いないが、それには多大なアノテーションコストがかかる。一方、セグメンテーションネットワークに頼れば、このコストを軽減することができる。トレーニングのために、最初に人間によるアノテーションが必要であるが、これによって、大量の画像を無料でセグメンテーションすることができる。残念ながら、我々の手法の全体的な有効性は、学習されたセグメンテーションモデルの精度に影響されることは避けられない。しかし、セグメンテーションマスクで画像に注釈を付けることは、深度注釈[63, 27]に比べて、間違いなく、はるかに少ない労力で済むと我々は考えている。したがって、前述の両方のアプローチを検討することにした。   読者は、我々の直感の結果として、ToMオブジェクトを扱うための深度ネットワークのトレーニングは不要かもしれない - 実際、深度を推定する前に、展開時にそのようなオブジェクトをセグメント化し、インペイントすれば十分であろう、と反論するかもしれない。しかし、そのような方法論は、ToMオブジェクトをセグメント化するために訓練されたモデルの実際の精度に大きく依存することになり、一般化することが認められないと反論する。さらに、無視できない計算コスト、つまり2つ目のネットワークによる推論が追加されることになる。これとは逆に、オフラインでのトレーニングやファインチューニングを行うことで、人間が作成したアノテーションを利用することができ（利用可能な場合）、トレーニングされたネットワークは、ToM表面の奥行きを適切に推定する方法を学習し、2つ目のネットワークを取り除くことができる可能性がある。我々の実験では、前者の戦略が効果的でないことを強調する一方で、我々のアプローチで奥行きモデルを微調整することにより、精度の大幅な向上を達成する。   残りの部分では、ToMオブジェクトを扱うための我々の方法論について述べる。画像Iのデータセットが与えられると、図2にスケッチした我々のパイプラインは次のように構築される：i)表面ラベリング、ii)インペインティングと蒸留、iii)仮想ラベル上での深度ネットワークの微調整。さらに、このパイプラインをどのように修正すれば、深いステレオネットワークも微調整できるかを示す。

DeepL.com（無料版）で翻訳しました。